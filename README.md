
### Education					                                                             			    	                                           
- M.A., Quantitative Methods in the Social Sciences â€“ Data Science Focus  | Columbia Uuniversity (_May 2025_)
- B.S., Political Science â€“ Data Analytics & B.A., Communication | University of California, San Diego (_May 2022_)
      		    		                          
### Projects & Publication 
#### AI Trust & Governance 
Cultural Fidelity in Large-Language Models: An Evaluation of Online Language Resources as a Driver of Model Performance in Value Representation
**Cultural Fidelity in Large-Language Models: An Evaluation of Online Language Resources as a Driver of Model Performance in Value Representation**  
**Sharif Kazemi, Gloria Gerhardt, Jonty Katz, Caroline Ida Kuria, Estelle Pan, Umang Prabhakar**

This study examines how cultural familiarity and digital language resources affect the performance of large language models (LLMs). Key findings include:

- **44%** of the variance in GPT-4oâ€™s ability to reflect societal values (measured using World Values Survey) was **correlated with the availability of digital resources** in a language.
- GPT-4-turbo showed an even stronger correlation (**72%**), indicating expanded efforts to improve model alignment beyond scraped web data.
- **Low-resource languages**, primarily in the Global South, had error rates **five times higher** than those of high-resource languages.
- We built one of the **largest multilingual WVS datasets**, covering **21 country-language pairs** and **94 survey questions per pair**, validated by native speakers.

ðŸ“„ link : https://arxiv.org/abs/2410.10489
